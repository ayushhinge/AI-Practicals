import nltk
import spacy
from collections import Counter
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# Download necessary NLTK resources
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('averaged_perceptron_tagger')

# Load SpaCy NLP model
nlp = spacy.load("en_core_web_sm")

# Sample text input
text = """Natural Language Processing (NLP) is a field of Artificial Intelligence 
(AI) that focuses on the interaction between computers and humans using natural language.
The goal is to enable computers to understand, interpret, and generate human 
language in a useful way."""

# **Step 1: Tokenization**
tokens = word_tokenize(text)
print("\n**Tokenized Words:**\n", tokens)

# **Step 2: Word Frequency Count**
word_freq = Counter(tokens)
print("\n**Word Frequency Count:**\n", word_freq)

# **Step 3: Stopword Removal**
stop_words = set(stopwords.words("english"))
filtered_tokens = [word for word in tokens if word.lower() not in stop_words]
print("\n**After Stopword Removal:**\n", filtered_tokens)

# **Step 4: POS Tagging**
pos_tags = nltk.pos_tag(filtered_tokens)
print("\n**POS Tagging (NLTK):**\n", pos_tags)

# **Step 5: AI-based POS Tagging using SpaCy**
doc = nlp(text)
print("\n**POS Tagging (SpaCy):**")
for token in doc:
    print(f"{token.text} --> {token.pos_}")
